{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JHU COVID-19 Data Pull and Clean Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Neil\\\\Documents\\\\Projects\\\\COVID-19\\\\COVID-19\\\\scripts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in necessary libraries\n",
    "for name in dir():\n",
    "    if not name.startswith('_'):\n",
    "        del globals()[name]\n",
    "\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>3/31/20</th>\n",
       "      <th>4/1/20</th>\n",
       "      <th>4/2/20</th>\n",
       "      <th>4/3/20</th>\n",
       "      <th>4/4/20</th>\n",
       "      <th>4/5/20</th>\n",
       "      <th>4/6/20</th>\n",
       "      <th>4/7/20</th>\n",
       "      <th>4/8/20</th>\n",
       "      <th>4/9/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>237</td>\n",
       "      <td>273</td>\n",
       "      <td>281</td>\n",
       "      <td>299</td>\n",
       "      <td>349</td>\n",
       "      <td>367</td>\n",
       "      <td>423</td>\n",
       "      <td>444</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>243</td>\n",
       "      <td>259</td>\n",
       "      <td>277</td>\n",
       "      <td>304</td>\n",
       "      <td>333</td>\n",
       "      <td>361</td>\n",
       "      <td>377</td>\n",
       "      <td>383</td>\n",
       "      <td>400</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>716</td>\n",
       "      <td>847</td>\n",
       "      <td>986</td>\n",
       "      <td>1171</td>\n",
       "      <td>1251</td>\n",
       "      <td>1320</td>\n",
       "      <td>1423</td>\n",
       "      <td>1468</td>\n",
       "      <td>1572</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>376</td>\n",
       "      <td>390</td>\n",
       "      <td>428</td>\n",
       "      <td>439</td>\n",
       "      <td>466</td>\n",
       "      <td>501</td>\n",
       "      <td>525</td>\n",
       "      <td>545</td>\n",
       "      <td>564</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region      Lat     Long  1/22/20  1/23/20  1/24/20  \\\n",
       "0            NaN    Afghanistan  33.0000  65.0000        0        0        0   \n",
       "1            NaN        Albania  41.1533  20.1683        0        0        0   \n",
       "2            NaN        Algeria  28.0339   1.6596        0        0        0   \n",
       "3            NaN        Andorra  42.5063   1.5218        0        0        0   \n",
       "4            NaN         Angola -11.2027  17.8739        0        0        0   \n",
       "\n",
       "   1/25/20  1/26/20  1/27/20  ...  3/31/20  4/1/20  4/2/20  4/3/20  4/4/20  \\\n",
       "0        0        0        0  ...      174     237     273     281     299   \n",
       "1        0        0        0  ...      243     259     277     304     333   \n",
       "2        0        0        0  ...      716     847     986    1171    1251   \n",
       "3        0        0        0  ...      376     390     428     439     466   \n",
       "4        0        0        0  ...        7       8       8       8      10   \n",
       "\n",
       "   4/5/20  4/6/20  4/7/20  4/8/20  4/9/20  \n",
       "0     349     367     423     444     484  \n",
       "1     361     377     383     400     409  \n",
       "2    1320    1423    1468    1572    1666  \n",
       "3     501     525     545     564     583  \n",
       "4      14      16      17      19      19  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process time-series data\n",
    "c_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Confirmed_archived_0325.csv'\n",
    "c_g_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "d_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Deaths_archived_0325.csv'\n",
    "d_g_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "r_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Recovered_archived_0325.csv'\n",
    "\n",
    "c = pd.read_csv(c_url)\n",
    "c_g = pd.read_csv(c_g_url)\n",
    "d = pd.read_csv(d_url)\n",
    "d_g = pd.read_csv(d_g_url)\n",
    "r = pd.read_csv(r_url)\n",
    "\n",
    "c_g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neil\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>date</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country/Region      Lat     Long Province/State  confirmed       date  \\\n",
       "0    Afghanistan  33.0000  65.0000            NaN        0.0 2020-01-22   \n",
       "1        Albania  41.1533  20.1683            NaN        0.0 2020-01-22   \n",
       "2        Algeria  28.0339   1.6596            NaN        0.0 2020-01-22   \n",
       "3        Andorra  42.5063   1.5218            NaN        0.0 2020-01-22   \n",
       "4         Angola -11.2027  17.8739            NaN        0.0 2020-01-22   \n",
       "\n",
       "   deaths  recovered  \n",
       "0     0.0        0.0  \n",
       "1     0.0        0.0  \n",
       "2     0.0        0.0  \n",
       "3     0.0        0.0  \n",
       "4     0.0        0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpivot dataframes\n",
    "c = c.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'confirmed')\n",
    "c_g = c_g.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'confirmed')\n",
    "d = d.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'deaths')\n",
    "d_g = d_g.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'deaths')\n",
    "r = r.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'recovered')\n",
    "\n",
    "# Convert from string to date\n",
    "c['date'] = pd.to_datetime(c['date'])\n",
    "c_g['date'] = pd.to_datetime(c_g['date'])\n",
    "d['date'] = pd.to_datetime(d['date'])\n",
    "d_g['date'] = pd.to_datetime(d_g['date'])\n",
    "r['date'] = pd.to_datetime(r['date'])\n",
    "\n",
    "# Remove US from c_g and d_g\n",
    "c_g = c_g[c_g['Country/Region']!='US']\n",
    "d_g = d_g[d_g['Country/Region']!='US']\n",
    "\n",
    "# Only keep the 50 states and a few special regions (get rid of the county level data) from c, g, and r\n",
    "states_list = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', \n",
    "               'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', \n",
    "               'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', \n",
    "               'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', \n",
    "               'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', \n",
    "               'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', \n",
    "               'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', \n",
    "               'Wyoming', 'American Samoa', 'Diamond Princess', 'Grand Princess', 'Guam', \n",
    "               'Northern Mariana Islands', 'Puerto Rico', 'Virgin Islands']\n",
    "\n",
    "c = c[(c['Country/Region']!='US') | ((c['Country/Region']=='US') & (c['Province/State'].isin(states_list)))]\n",
    "d = d[(d['Country/Region']!='US') | ((d['Country/Region']=='US') & (d['Province/State'].isin(states_list)))]\n",
    "r = r[(r['Country/Region']!='US') | ((r['Country/Region']=='US') & (r['Province/State'].isin(states_list)))]\n",
    "\n",
    "# Truncate c,d, and r to end in 3/22 - keep only US in c and d\n",
    "c = c[(c['date'] <= '2020-03-22') & (c['Country/Region']=='US')]\n",
    "d = d[(d['date'] <= '2020-03-22') & (d['Country/Region']=='US')]\n",
    "r = r[r['date'] <= '2020-03-22']\n",
    "\n",
    "# Get state locations from c\n",
    "#states_loc = c.groupby('Province/State', as_index=False).agg({'Lat': 'mean', 'Long': 'mean'})\n",
    "#states_list = ['Alabama', 'Alaska', 'American Samoa', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Guam', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Minor Outlying Islands', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Northern Mariana Islands', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'U.S. Virgin Islands', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
    "#states_loc = states_loc[states_loc['Province/State'].isin(states_list)]\n",
    "\n",
    "# Merge and append everything together\n",
    "df = c_g.merge(d_g, how='outer', left_on = ['Province/State', 'Country/Region', 'Lat', 'Long', 'date'],\n",
    "                    right_on = ['Province/State', 'Country/Region', 'Lat', 'Long', 'date'])\n",
    "df = df.merge(r, how='outer', left_on = ['Province/State', 'Country/Region', 'Lat', 'Long', 'date'],\n",
    "                    right_on = ['Province/State', 'Country/Region', 'Lat', 'Long', 'date'])\n",
    "df = df.append(c)\n",
    "df = df.append(d)\n",
    "\n",
    "# Get the latitudes and longitudes of every province/state in the dataframe\n",
    "locations = df.groupby(['Country/Region', 'Province/State'], as_index=False).agg({'Lat': 'mean', 'Long': 'mean'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No daily file available yet for today\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>County</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45001.0</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>US</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22001.0</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>US</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>89</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16001.0</td>\n",
       "      <td>Ada</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>US</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>447</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19001.0</td>\n",
       "      <td>Adair</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>US</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      FIPS     County  Province/State Country/Region        Lat        Long  \\\n",
       "0  45001.0  Abbeville  South Carolina             US  34.223334  -82.461707   \n",
       "1  22001.0     Acadia       Louisiana             US  30.295065  -92.414197   \n",
       "2  51001.0   Accomack        Virginia             US  37.767072  -75.632346   \n",
       "3  16001.0        Ada           Idaho             US  43.452658 -116.241552   \n",
       "4  19001.0      Adair            Iowa             US  41.330756  -94.471059   \n",
       "\n",
       "   confirmed  deaths  recovered        date  \n",
       "0          7       0          0  2020-04-09  \n",
       "1         89       3          0  2020-04-09  \n",
       "2         11       0          0  2020-04-09  \n",
       "3        447       5          0  2020-04-09  \n",
       "4          1       0          0  2020-04-09  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most recent daily reports data\n",
    "# First see if there is a file for today\n",
    "\n",
    "try:\n",
    "    del daily\n",
    "except:\n",
    "    print(\"\")\n",
    "\n",
    "daily_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/'+date.today().strftime(\"%m-%d-%Y\")+'.csv'\n",
    "try:\n",
    "    daily = pd.read_csv(daily_url)\n",
    "    daily['date'] = date.today()\n",
    "except:\n",
    "    print('No daily file available yet for today')\n",
    "day = date.today() - timedelta(days=1)\n",
    "\n",
    "# If no daily report file for today, try yesterday's\n",
    "try:\n",
    "    daily\n",
    "except:   \n",
    "    daily_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/'+(date.today() - timedelta(days=1)).strftime(\"%m-%d-%Y\")+'.csv'\n",
    "    daily = pd.read_csv(daily_url)\n",
    "    daily['date'] = date.today() - timedelta(days=1)\n",
    "    day = date.today() - timedelta(days=2)\n",
    "    \n",
    "#print(type(day))\n",
    "#day > datetime(2020, 3, 22).date()\n",
    "\n",
    "# Loop through days and get the remaining data\n",
    "while day > datetime(2020, 3, 22).date():\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/'+day.strftime(\"%m-%d-%Y\")+'.csv'\n",
    "    temp = pd.read_csv(url)\n",
    "    temp['date'] = day\n",
    "    daily = daily.append(temp)\n",
    "    day = day - timedelta(days=1)\n",
    "    \n",
    "# Convert Last_Update to date\n",
    "# Drop unnecessary columns\n",
    "daily = daily.drop(columns=['Last_Update', 'Combined_Key', 'Active'])\n",
    "daily = daily.rename(columns={'Long_': 'Long', 'Admin2': 'County', 'Province_State': 'Province/State', \n",
    "                              'Country_Region': 'Country/Region', 'Recovered': 'recovered', \n",
    "                              'Confirmed': 'confirmed', 'Deaths': 'deaths'})\n",
    "\n",
    "# Remove the US and Canada total recovered rows\n",
    "daily = daily[daily['Province/State']!='Recovered']\n",
    "\n",
    "# Fix Falkland Islands name change\n",
    "daily['Province/State'][daily['Province/State']=='Falkland Islands (Islas Malvinas)'] = 'Falkland Islands (Malvinas)'\n",
    "\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Maniuplate the daily report\n",
    "\n",
    "# Create a US by county dataset\n",
    "us_counties = daily.loc[(daily['Country/Region']==\"US\") & (daily['County'].notna())]\n",
    "us_counties['active'] = us_counties['confirmed'] - us_counties['deaths'] - us_counties['recovered']\n",
    "\n",
    "# Remove US counties from daily dataset\n",
    "daily_us = daily.loc[(daily['Country/Region']=='US') & (daily['County'].isna())]\n",
    "daily_us = daily_us.drop(columns=['County', 'FIPS'])\n",
    "daily = daily.loc[daily['Country/Region']!='US']\n",
    "daily = daily.drop(columns=['FIPS'])\n",
    "daily = daily.rename(columns={'recovered': 'recovered_new'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>587</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State        date  confirmed  deaths  recovered Country/Region  \\\n",
       "0        Alabama  2020-03-23        196       0          0             US   \n",
       "1        Alabama  2020-03-24        242       0          0             US   \n",
       "2        Alabama  2020-03-25        381       1          0             US   \n",
       "3        Alabama  2020-03-26        517       1          0             US   \n",
       "4        Alabama  2020-03-27        587       4          0             US   \n",
       "\n",
       "       Lat     Long  \n",
       "0  32.3182 -86.9023  \n",
       "1  32.3182 -86.9023  \n",
       "2  32.3182 -86.9023  \n",
       "3  32.3182 -86.9023  \n",
       "4  32.3182 -86.9023  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate US county data to state level\n",
    "states = us_counties.groupby(['Province/State', 'date'], as_index=False).agg({'confirmed': 'sum', 'deaths': 'sum', 'recovered': 'sum'})\n",
    "#states['Country/Region'] = \"US\"\n",
    "\n",
    "# Bring in latitudes and longitudes from States_loc\n",
    "states = states.merge(locations, how='inner', on=['Province/State'])\n",
    "states.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge in recovered for non-US regions\n",
    "daily = daily.drop(columns=['County', 'confirmed', 'deaths', 'Lat', 'Long'])\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "df = df.merge(daily, how='outer', on=['Country/Region', 'Province/State', 'date'])\n",
    "\n",
    "# Replace NA's in recovered column with new recovered values\n",
    "df['recovered'].fillna(df['recovered_new'], inplace=True)\n",
    "df = df.drop(columns=['recovered_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in lat's and long's from locations df to the daily_us df\n",
    "#daily_us = daily_us.merge(locations, how='inner', on=['Province/State'])\n",
    "\n",
    "# Append daily_us and states to the df\n",
    "df = df.append(daily_us)\n",
    "df = df.append(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NAs with 0s, convert from floats to ints\n",
    "\n",
    "df['deaths'].fillna(0, inplace=True)\n",
    "df['deaths'] = df['deaths'].astype(int)\n",
    "df['confirmed'].fillna(0, inplace=True)\n",
    "df['confirmed'] = df['confirmed'].astype(int)\n",
    "df['recovered'].fillna(0, inplace=True)\n",
    "df['recovered'] = df['recovered'].astype(int)\n",
    "\n",
    "# Correct the lat and long for the cruise ships in the newer data\n",
    "df.loc[(df['Country/Region']=='Cruise Ship') & (df['Province/State']=='Diamond Princess'), 'Lat'] = df[(df['Province/State']=='Diamond Princess') & (df['Country/Region']=='Cruise Ship') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Lat': 'mean'})['Lat'][0]\n",
    "df.loc[(df['Country/Region']=='Cruise Ship') & (df['Province/State']=='Diamond Princess'), 'Long'] = df[(df['Province/State']=='Diamond Princess') & (df['Country/Region']=='Cruise Ship') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Long': 'mean'})['Long'][0]\n",
    "df.loc[(df['Country/Region']=='US') & (df['Province/State']=='Diamond Princess'), 'Lat'] = df[(df['Province/State']=='Diamond Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Lat': 'mean'})['Lat'][0]\n",
    "df.loc[(df['Country/Region']=='US') & (df['Province/State']=='Diamond Princess'), 'Long'] = df[(df['Province/State']=='Diamond Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Long': 'mean'})['Long'][0]\n",
    "df.loc[(df['Country/Region']=='US') & (df['Province/State']=='Grand Princess'), 'Lat'] = df[(df['Province/State']=='Grand Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Lat': 'mean'})['Lat'][0]\n",
    "df.loc[(df['Country/Region']=='US') & (df['Province/State']=='Grand Princess'), 'Long'] = df[(df['Province/State']=='Grand Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Long': 'mean'})['Long'][0]\n",
    "\n",
    "#df.loc[(df['Country/Region']=='United Kingdom') & (df['Province/State']=='Grand Princess'), 'Lat'] = df[(df['Province/State']=='Grand Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Lat': 'mean'})['Lat'][0]\n",
    "#df.loc[(df['Country/Region']=='United Kingdom') & (df['Province/State']=='Grand Princess'), 'Long'] = df[(df['Province/State']=='Grand Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Long': 'mean'})['Long'][0]\n",
    "\n",
    "\n",
    "\n",
    "df = df.round({'Lat': 3, 'Long': 3})\n",
    "\n",
    "df = df.sort_values(by=['Country/Region', 'Province/State', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit US counties to most recent day\n",
    "us_counties = us_counties[us_counties['date']==us_counties['date'].max()]\n",
    "us_counties = us_counties.sort_values(by=['County'])\n",
    "\n",
    "# Convert FIPS to strings\n",
    "us_counties = us_counties[us_counties['FIPS'].notna()]\n",
    "us_counties['FIPS'] = us_counties['FIPS'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv and remove SQL results\n",
    "os.chdir('..')\n",
    "df.to_csv('ts.csv', index=False)\n",
    "us_counties.to_csv('counties.csv', index=False)\n",
    "\n",
    "try:\n",
    "    os.remove('.\\\\output\\\\region_latest.csv')\n",
    "except:\n",
    "    print(\"File doesn't exist\")\n",
    "try:\n",
    "    os.remove('.\\\\output\\\\region_province_ts.csv')\n",
    "except:\n",
    "    print(\"File doesn't exist\")\n",
    "try:\n",
    "    os.remove('.\\\\output\\\\ts_chart.csv')\n",
    "except:\n",
    "    print(\"File doesn't exist\")\n",
    "\n",
    "os.chdir(\".\\\\scripts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
