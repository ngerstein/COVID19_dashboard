{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JHU COVID-19 Data Pull and Clean Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Neil\\\\Documents\\\\Projects\\\\COVID-19\\\\COVID-19\\\\scripts'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in necessary libraries\n",
    "for name in dir():\n",
    "    if not name.startswith('_'):\n",
    "        del globals()[name]\n",
    "\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>4/13/20</th>\n",
       "      <th>4/14/20</th>\n",
       "      <th>4/15/20</th>\n",
       "      <th>4/16/20</th>\n",
       "      <th>4/17/20</th>\n",
       "      <th>4/18/20</th>\n",
       "      <th>4/19/20</th>\n",
       "      <th>4/20/20</th>\n",
       "      <th>4/21/20</th>\n",
       "      <th>4/22/20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>665</td>\n",
       "      <td>714</td>\n",
       "      <td>784</td>\n",
       "      <td>840</td>\n",
       "      <td>906</td>\n",
       "      <td>933</td>\n",
       "      <td>996</td>\n",
       "      <td>1026</td>\n",
       "      <td>1092</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>467</td>\n",
       "      <td>475</td>\n",
       "      <td>494</td>\n",
       "      <td>518</td>\n",
       "      <td>539</td>\n",
       "      <td>548</td>\n",
       "      <td>562</td>\n",
       "      <td>584</td>\n",
       "      <td>609</td>\n",
       "      <td>634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1983</td>\n",
       "      <td>2070</td>\n",
       "      <td>2160</td>\n",
       "      <td>2268</td>\n",
       "      <td>2418</td>\n",
       "      <td>2534</td>\n",
       "      <td>2629</td>\n",
       "      <td>2718</td>\n",
       "      <td>2811</td>\n",
       "      <td>2910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>646</td>\n",
       "      <td>659</td>\n",
       "      <td>673</td>\n",
       "      <td>673</td>\n",
       "      <td>696</td>\n",
       "      <td>704</td>\n",
       "      <td>713</td>\n",
       "      <td>717</td>\n",
       "      <td>717</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State Country/Region      Lat     Long  1/22/20  1/23/20  1/24/20  \\\n",
       "0            NaN    Afghanistan  33.0000  65.0000        0        0        0   \n",
       "1            NaN        Albania  41.1533  20.1683        0        0        0   \n",
       "2            NaN        Algeria  28.0339   1.6596        0        0        0   \n",
       "3            NaN        Andorra  42.5063   1.5218        0        0        0   \n",
       "4            NaN         Angola -11.2027  17.8739        0        0        0   \n",
       "\n",
       "   1/25/20  1/26/20  1/27/20  ...  4/13/20  4/14/20  4/15/20  4/16/20  \\\n",
       "0        0        0        0  ...      665      714      784      840   \n",
       "1        0        0        0  ...      467      475      494      518   \n",
       "2        0        0        0  ...     1983     2070     2160     2268   \n",
       "3        0        0        0  ...      646      659      673      673   \n",
       "4        0        0        0  ...       19       19       19       19   \n",
       "\n",
       "   4/17/20  4/18/20  4/19/20  4/20/20  4/21/20  4/22/20  \n",
       "0      906      933      996     1026     1092     1176  \n",
       "1      539      548      562      584      609      634  \n",
       "2     2418     2534     2629     2718     2811     2910  \n",
       "3      696      704      713      717      717      723  \n",
       "4       19       24       24       24       24       25  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process time-series data\n",
    "c_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Confirmed_archived_0325.csv'\n",
    "c_g_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "d_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Deaths_archived_0325.csv'\n",
    "d_g_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'\n",
    "r_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/archived_data/archived_time_series/time_series_19-covid-Recovered_archived_0325.csv'\n",
    "\n",
    "c = pd.read_csv(c_url)\n",
    "c_g = pd.read_csv(c_g_url)\n",
    "d = pd.read_csv(d_url)\n",
    "d_g = pd.read_csv(d_g_url)\n",
    "r = pd.read_csv(r_url)\n",
    "\n",
    "c_g.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neil\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>date</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.0000</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>41.1533</td>\n",
       "      <td>20.1683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.0339</td>\n",
       "      <td>1.6596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.5063</td>\n",
       "      <td>1.5218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.2027</td>\n",
       "      <td>17.8739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Country/Region      Lat     Long Province/State  confirmed       date  \\\n",
       "0    Afghanistan  33.0000  65.0000            NaN        0.0 2020-01-22   \n",
       "1        Albania  41.1533  20.1683            NaN        0.0 2020-01-22   \n",
       "2        Algeria  28.0339   1.6596            NaN        0.0 2020-01-22   \n",
       "3        Andorra  42.5063   1.5218            NaN        0.0 2020-01-22   \n",
       "4         Angola -11.2027  17.8739            NaN        0.0 2020-01-22   \n",
       "\n",
       "   deaths  recovered  \n",
       "0     0.0        0.0  \n",
       "1     0.0        0.0  \n",
       "2     0.0        0.0  \n",
       "3     0.0        0.0  \n",
       "4     0.0        0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpivot dataframes\n",
    "c = c.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'confirmed')\n",
    "c_g = c_g.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'confirmed')\n",
    "d = d.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'deaths')\n",
    "d_g = d_g.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'deaths')\n",
    "r = r.melt(id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], var_name = 'date', value_name = 'recovered')\n",
    "\n",
    "# Convert from string to date\n",
    "c['date'] = pd.to_datetime(c['date'])\n",
    "c_g['date'] = pd.to_datetime(c_g['date'])\n",
    "d['date'] = pd.to_datetime(d['date'])\n",
    "d_g['date'] = pd.to_datetime(d_g['date'])\n",
    "r['date'] = pd.to_datetime(r['date'])\n",
    "\n",
    "# Remove US from c_g and d_g\n",
    "c_g = c_g[c_g['Country/Region']!='US']\n",
    "d_g = d_g[d_g['Country/Region']!='US']\n",
    "\n",
    "# Only keep the 50 states and a few special regions (get rid of the county level data) from c, g, and r\n",
    "states_list = ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', \n",
    "               'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', \n",
    "               'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', \n",
    "               'Michigan', 'Minnesota', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', \n",
    "               'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', \n",
    "               'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Rhode Island', 'South Carolina', 'South Dakota', \n",
    "               'Tennessee', 'Texas', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', \n",
    "               'Wyoming', 'American Samoa', 'Diamond Princess', 'Grand Princess', 'Guam', \n",
    "               'Northern Mariana Islands', 'Puerto Rico', 'Virgin Islands']\n",
    "\n",
    "c = c[(c['Country/Region']!='US') | ((c['Country/Region']=='US') & (c['Province/State'].isin(states_list)))]\n",
    "d = d[(d['Country/Region']!='US') | ((d['Country/Region']=='US') & (d['Province/State'].isin(states_list)))]\n",
    "r = r[(r['Country/Region']!='US') | ((r['Country/Region']=='US') & (r['Province/State'].isin(states_list)))]\n",
    "\n",
    "# Truncate c,d, and r to end in 3/22 - keep only US in c and d\n",
    "c = c[(c['date'] <= '2020-03-22') & (c['Country/Region']=='US')]\n",
    "d = d[(d['date'] <= '2020-03-22') & (d['Country/Region']=='US')]\n",
    "r = r[r['date'] <= '2020-03-22']\n",
    "\n",
    "# Get state locations from c\n",
    "#states_loc = c.groupby('Province/State', as_index=False).agg({'Lat': 'mean', 'Long': 'mean'})\n",
    "#states_list = ['Alabama', 'Alaska', 'American Samoa', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia', 'Guam', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Minor Outlying Islands', 'Mississippi', 'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico', 'New York', 'North Carolina', 'North Dakota', 'Northern Mariana Islands', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'U.S. Virgin Islands', 'Utah', 'Vermont', 'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']\n",
    "#states_loc = states_loc[states_loc['Province/State'].isin(states_list)]\n",
    "\n",
    "# Merge and append everything together\n",
    "df = c_g.merge(d_g, how='outer', left_on = ['Province/State', 'Country/Region', 'Lat', 'Long', 'date'],\n",
    "                    right_on = ['Province/State', 'Country/Region', 'Lat', 'Long', 'date'])\n",
    "df = df.merge(r, how='outer', left_on = ['Province/State', 'Country/Region', 'Lat', 'Long', 'date'],\n",
    "                    right_on = ['Province/State', 'Country/Region', 'Lat', 'Long', 'date'])\n",
    "df = df.append(c)\n",
    "df = df.append(d)\n",
    "\n",
    "# Get the latitudes and longitudes of every province/state in the dataframe\n",
    "locations = df.groupby(['Country/Region', 'Province/State'], as_index=False).agg({'Lat': 'mean', 'Long': 'mean'})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No daily file available yet for today\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>County</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>recovered</th>\n",
       "      <th>deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>Abbeville</td>\n",
       "      <td>45001.0</td>\n",
       "      <td>US</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>34.223334</td>\n",
       "      <td>-82.461707</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>Acadia</td>\n",
       "      <td>22001.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>30.295065</td>\n",
       "      <td>-92.414197</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>Accomack</td>\n",
       "      <td>51001.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>37.767072</td>\n",
       "      <td>-75.632346</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>Ada</td>\n",
       "      <td>16001.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>43.452658</td>\n",
       "      <td>-116.241552</td>\n",
       "      <td>622</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>Adair</td>\n",
       "      <td>19001.0</td>\n",
       "      <td>US</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>41.330756</td>\n",
       "      <td>-94.471059</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     County     FIPS Country/Region  Province/State        Lat  \\\n",
       "0  2020-04-22  Abbeville  45001.0             US  South Carolina  34.223334   \n",
       "1  2020-04-22     Acadia  22001.0             US       Louisiana  30.295065   \n",
       "2  2020-04-22   Accomack  51001.0             US        Virginia  37.767072   \n",
       "3  2020-04-22        Ada  16001.0             US           Idaho  43.452658   \n",
       "4  2020-04-22      Adair  19001.0             US            Iowa  41.330756   \n",
       "\n",
       "         Long  confirmed  recovered  deaths  \n",
       "0  -82.461707         22          0       0  \n",
       "1  -92.414197        117          0       7  \n",
       "2  -75.632346         59          0       1  \n",
       "3 -116.241552        622          0      12  \n",
       "4  -94.471059          1          0       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the most recent daily reports data\n",
    "# First see if there is a file for today\n",
    "\n",
    "try:\n",
    "    del daily\n",
    "except:\n",
    "    print(\"\")\n",
    "\n",
    "daily_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/'+date.today().strftime(\"%m-%d-%Y\")+'.csv'\n",
    "try:\n",
    "    daily = pd.read_csv(daily_url)\n",
    "    daily['date'] = date.today()\n",
    "except:\n",
    "    print('No daily file available yet for today')\n",
    "day = date.today() - timedelta(days=1)\n",
    "\n",
    "# If no daily report file for today, try yesterday's\n",
    "try:\n",
    "    daily\n",
    "except:   \n",
    "    daily_url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/'+(date.today() - timedelta(days=1)).strftime(\"%m-%d-%Y\")+'.csv'\n",
    "    daily = pd.read_csv(daily_url)\n",
    "    daily['date'] = date.today() - timedelta(days=1)\n",
    "    day = date.today() - timedelta(days=2)\n",
    "    \n",
    "#print(type(day))\n",
    "#day > datetime(2020, 3, 22).date()\n",
    "\n",
    "# Loop through days and get the remaining data\n",
    "while day > datetime(2020, 3, 22).date():\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/'+day.strftime(\"%m-%d-%Y\")+'.csv'\n",
    "    temp = pd.read_csv(url)\n",
    "    temp['date'] = day\n",
    "    daily = daily.append(temp)\n",
    "    day = day - timedelta(days=1)\n",
    "    \n",
    "# Convert Last_Update to date\n",
    "# Drop unnecessary columns\n",
    "daily = daily.drop(columns=['Last_Update', 'Combined_Key', 'Active'])\n",
    "daily = daily.rename(columns={'Long_': 'Long', 'Admin2': 'County', 'Province_State': 'Province/State', \n",
    "                              'Country_Region': 'Country/Region', 'Recovered': 'recovered', \n",
    "                              'Confirmed': 'confirmed', 'Deaths': 'deaths'})\n",
    "\n",
    "# Remove the US and Canada total recovered rows\n",
    "daily = daily[daily['Province/State']!='Recovered']\n",
    "\n",
    "# Fix Falkland Islands name change\n",
    "daily['Province/State'][daily['Province/State']=='Falkland Islands (Islas Malvinas)'] = 'Falkland Islands (Malvinas)'\n",
    "\n",
    "# Keep only necessary columns. NOTE: New variables like tested, incident rate, and hospitalization rates are available\n",
    "daily = daily[['date', 'County', 'FIPS', 'Country/Region', 'Province/State', 'Lat', 'Long', 'confirmed', 'recovered', 'deaths']]\n",
    "\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Neil\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Maniuplate the daily report\n",
    "\n",
    "# Create a US by county dataset\n",
    "us_counties = daily.loc[(daily['Country/Region']==\"US\") & (daily['County'].notna())]\n",
    "us_counties['active'] = us_counties['confirmed'] - us_counties['deaths'] - us_counties['recovered']\n",
    "\n",
    "# Remove US counties from daily dataset\n",
    "daily_us = daily.loc[(daily['Country/Region']=='US') & (daily['County'].isna())]\n",
    "daily_us = daily_us.drop(columns=['County', 'FIPS'])\n",
    "daily = daily.loc[daily['Country/Region']!='US']\n",
    "daily = daily.drop(columns=['FIPS'])\n",
    "daily = daily.rename(columns={'recovered': 'recovered_new'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>date</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-23</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-24</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>517</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>587</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>32.3182</td>\n",
       "      <td>-86.9023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State        date  confirmed  deaths  recovered Country/Region  \\\n",
       "0        Alabama  2020-03-23        196       0          0             US   \n",
       "1        Alabama  2020-03-24        242       0          0             US   \n",
       "2        Alabama  2020-03-25        381       1          0             US   \n",
       "3        Alabama  2020-03-26        517       1          0             US   \n",
       "4        Alabama  2020-03-27        587       4          0             US   \n",
       "\n",
       "       Lat     Long  \n",
       "0  32.3182 -86.9023  \n",
       "1  32.3182 -86.9023  \n",
       "2  32.3182 -86.9023  \n",
       "3  32.3182 -86.9023  \n",
       "4  32.3182 -86.9023  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate US county data to state level\n",
    "states = us_counties.groupby(['Province/State', 'date'], as_index=False).agg({'confirmed': 'sum', 'deaths': 'sum', 'recovered': 'sum'})\n",
    "#states['Country/Region'] = \"US\"\n",
    "\n",
    "# Bring in latitudes and longitudes from States_loc\n",
    "states = states.merge(locations, how='inner', on=['Province/State'])\n",
    "states.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge in recovered for non-US regions\n",
    "daily = daily.drop(columns=['County', 'confirmed', 'deaths', 'Lat', 'Long'])\n",
    "df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "df = df.merge(daily, how='outer', on=['Country/Region', 'Province/State', 'date'])\n",
    "\n",
    "# Replace NA's in recovered column with new recovered values\n",
    "df['recovered'].fillna(df['recovered_new'], inplace=True)\n",
    "df = df.drop(columns=['recovered_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Province/State</th>\n",
       "      <th>recovered_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2830</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Anguilla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>China</td>\n",
       "      <td>Anhui</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2832</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>Aruba</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Australian Capital Territory</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  Country/Region                Province/State  recovered_new\n",
       "2829  2020-04-22          Canada                       Alberta              0\n",
       "2830  2020-04-22  United Kingdom                      Anguilla              1\n",
       "2831  2020-04-22           China                         Anhui            984\n",
       "2832  2020-04-22     Netherlands                         Aruba             68\n",
       "2833  2020-04-22       Australia  Australian Capital Territory             88"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge in lat's and long's from locations df to the daily_us df\n",
    "#daily_us = daily_us.merge(locations, how='inner', on=['Province/State'])\n",
    "\n",
    "# Append daily_us and states to the df\n",
    "df = df.append(daily_us)\n",
    "df = df.append(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NAs with 0s, convert from floats to ints\n",
    "\n",
    "df['deaths'].fillna(0, inplace=True)\n",
    "df['deaths'] = df['deaths'].astype(int)\n",
    "df['confirmed'].fillna(0, inplace=True)\n",
    "df['confirmed'] = df['confirmed'].astype(int)\n",
    "df['recovered'].fillna(0, inplace=True)\n",
    "df['recovered'] = df['recovered'].astype(int)\n",
    "\n",
    "# Correct the lat and long for the cruise ships in the newer data\n",
    "df.loc[(df['Country/Region']=='Cruise Ship') & (df['Province/State']=='Diamond Princess'), 'Lat'] = df[(df['Province/State']=='Diamond Princess') & (df['Country/Region']=='Cruise Ship') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Lat': 'mean'})['Lat'][0]\n",
    "df.loc[(df['Country/Region']=='Cruise Ship') & (df['Province/State']=='Diamond Princess'), 'Long'] = df[(df['Province/State']=='Diamond Princess') & (df['Country/Region']=='Cruise Ship') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Long': 'mean'})['Long'][0]\n",
    "df.loc[(df['Country/Region']=='US') & (df['Province/State']=='Diamond Princess'), 'Lat'] = df[(df['Province/State']=='Diamond Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Lat': 'mean'})['Lat'][0]\n",
    "df.loc[(df['Country/Region']=='US') & (df['Province/State']=='Diamond Princess'), 'Long'] = df[(df['Province/State']=='Diamond Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Long': 'mean'})['Long'][0]\n",
    "df.loc[(df['Country/Region']=='US') & (df['Province/State']=='Grand Princess'), 'Lat'] = df[(df['Province/State']=='Grand Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Lat': 'mean'})['Lat'][0]\n",
    "df.loc[(df['Country/Region']=='US') & (df['Province/State']=='Grand Princess'), 'Long'] = df[(df['Province/State']=='Grand Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Long': 'mean'})['Long'][0]\n",
    "\n",
    "#df.loc[(df['Country/Region']=='United Kingdom') & (df['Province/State']=='Grand Princess'), 'Lat'] = df[(df['Province/State']=='Grand Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Lat': 'mean'})['Lat'][0]\n",
    "#df.loc[(df['Country/Region']=='United Kingdom') & (df['Province/State']=='Grand Princess'), 'Long'] = df[(df['Province/State']=='Grand Princess') & (df['Country/Region']=='US') & (df['date']<datetime(2020,3,23).date())].groupby(['Country/Region', 'Province/State']).agg({'Long': 'mean'})['Long'][0]\n",
    "\n",
    "\n",
    "\n",
    "df = df.round({'Lat': 3, 'Long': 3})\n",
    "\n",
    "df = df.sort_values(by=['Country/Region', 'Province/State', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit US counties to most recent day\n",
    "us_counties_ts = us_counties\n",
    "us_counties = us_counties[us_counties['date']==us_counties['date'].max()]\n",
    "us_counties = us_counties.sort_values(by=['County'])\n",
    "\n",
    "# Convert FIPS to strings\n",
    "us_counties = us_counties[us_counties['FIPS'].notna()]\n",
    "us_counties['FIPS'] = us_counties['FIPS'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Neil\\\\Documents\\\\Projects\\\\COVID-19\\\\COVID-19\\\\scripts'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export csv and remove SQL results\n",
    "os.chdir('..')\n",
    "df.to_csv('ts.csv', index=False)\n",
    "us_counties.to_csv('counties.csv', index=False)\n",
    "us_counties_ts.to_csv('counties_ts.csv', index=False)\n",
    "\n",
    "try:\n",
    "    os.remove('.\\\\output\\\\region_latest.csv')\n",
    "except:\n",
    "    print(\"File doesn't exist\")\n",
    "try:\n",
    "    os.remove('.\\\\output\\\\region_province_ts.csv')\n",
    "except:\n",
    "    print(\"File doesn't exist\")\n",
    "try:\n",
    "    os.remove('.\\\\output\\\\region_province_ts_full.csv')\n",
    "except:\n",
    "    print(\"File doesn't exist\")\n",
    "try:\n",
    "    os.remove('.\\\\output\\\\ts_chart.csv')\n",
    "except:\n",
    "    print(\"File doesn't exist\")\n",
    "\n",
    "os.chdir(\".\\\\scripts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
